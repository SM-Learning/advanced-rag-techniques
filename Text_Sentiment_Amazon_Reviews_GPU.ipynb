{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3vnOCB17wop3CylbeLQUQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc7ToyM72MzL",
        "outputId": "3f90aac6-c57f-45f3-eee3-4d375fbf5117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m853.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Cell 1: Install Packages\n",
        "# =========================\n",
        "!pip install torch torchtext pandas numpy matplotlib seaborn tokenizers tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 2: Imports & Setup\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import gzip\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "import subprocess\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# GPU monitoring utility\n",
        "def get_gpu_stats():\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,nounits,noheader'],\n",
        "            stdout=subprocess.PIPE, text=True\n",
        "        )\n",
        "        stats = []\n",
        "        for idx, line in enumerate(result.stdout.strip().split('\\n')):\n",
        "            util, mem_used, mem_total = line.split(',')\n",
        "            stats.append({\n",
        "                'gpu': idx,\n",
        "                'utilization': float(util),\n",
        "                'mem_used': float(mem_used),\n",
        "                'mem_total': float(mem_total)\n",
        "            })\n",
        "        return stats\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "# For reproducibility\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "8Np0shX72O1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 3: Data Loading & Preprocessing\n",
        "# =========================\n",
        "\n",
        "# Download Amazon Books dataset (200K for grid search)\n",
        "DATA_URL = \"https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Books_5.json.gz\"\n",
        "DATA_FILE = \"Books_5.json.gz\"\n",
        "if not os.path.exists(DATA_FILE):\n",
        "    print(\"Downloading dataset...\")\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(DATA_URL, DATA_FILE)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Simple text cleaning\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def load_amazon_subset(filename, n_total=200_000):\n",
        "    records = []\n",
        "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, total=n_total):\n",
        "            rec = json.loads(line)\n",
        "            if 'reviewText' in rec and 'overall' in rec:\n",
        "                text = preprocess_text(rec['reviewText'])\n",
        "                records.append({'reviewText': text, 'overall': int(float(rec['overall']))})\n",
        "            if len(records) >= n_total:\n",
        "                break\n",
        "    df = pd.DataFrame(records)\n",
        "    df = df[df['overall'].isin([1,2,3,4,5])].dropna()\n",
        "    print(\"Class distribution:\\n\", df['overall'].value_counts())\n",
        "    return df\n",
        "\n",
        "df = load_amazon_subset(DATA_FILE, n_total=200_000)\n",
        "\n",
        "# BPE Tokenization\n",
        "bpe_tokenizer = ByteLevelBPETokenizer()\n",
        "bpe_tokenizer.train_from_iterator(df['reviewText'], vocab_size=50000, min_frequency=2, show_progress=True)\n",
        "bpe_tokenizer.enable_truncation(max_length=200)\n",
        "bpe_tokenizer.save_model(\".\", \"books_bpe\")\n",
        "bpe_tokenizer = ByteLevelBPETokenizer(\"books_bpe-vocab.json\", \"books_bpe-merges.txt\")\n",
        "bpe_tokenizer.enable_truncation(max_length=200)\n",
        "\n",
        "def encode_bpe(text):\n",
        "    return bpe_tokenizer.encode(text).ids\n",
        "\n",
        "MAX_LEN = 200\n",
        "def pad_seq(seq, max_len=MAX_LEN):\n",
        "    if len(seq) < max_len:\n",
        "        return seq + [0] * (max_len - len(seq))\n",
        "    else:\n",
        "        return seq[:max_len]\n",
        "\n",
        "df['bpe_ids'] = df['reviewText'].apply(lambda x: pad_seq(encode_bpe(x), MAX_LEN))\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.seqs = np.stack(df['bpe_ids'].values)\n",
        "        self.labels = df['overall'].values - 1  # 0-based classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.seqs[idx], dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "dataset = ReviewDataset(df)\n",
        "\n",
        "# Train/val/test split\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(dataset)), test_size=0.1, stratify=df['overall'], random_state=SEED\n",
        ")\n",
        "train_idx, val_idx = train_test_split(\n",
        "    train_idx, test_size=0.1, stratify=df.iloc[train_idx]['overall'], random_state=SEED\n",
        ")\n",
        "train_ds = Subset(dataset, train_idx)\n",
        "val_ds = Subset(dataset, val_idx)\n",
        "test_ds = Subset(dataset, test_idx)"
      ],
      "metadata": {
        "id": "_CUzIeVz2X0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 4: Model Architecture\n",
        "# =========================\n",
        "\n",
        "class CNN_BiLSTM_Attn(nn.Module):\n",
        "    def __init__(self, vocab_size=50000, embed_dim=128, cnn_out=150, lstm_hidden=128, num_heads=6, num_classes=5, dropout=0.3):\n",
        "        super().__init__()\n",
        "        assert (lstm_hidden * 2) % num_heads == 0, \"lstm_hidden*2 must be divisible by num_heads\"\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.conv3 = nn.Conv1d(embed_dim, cnn_out, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv1d(embed_dim, cnn_out, kernel_size=4, padding=2)\n",
        "        self.conv5 = nn.Conv1d(embed_dim, cnn_out, kernel_size=5, padding=2)\n",
        "        self.bn3 = nn.BatchNorm1d(cnn_out)\n",
        "        self.bn4 = nn.BatchNorm1d(cnn_out)\n",
        "        self.bn5 = nn.BatchNorm1d(cnn_out)\n",
        "        self.proj = nn.Linear(embed_dim, cnn_out * 3)\n",
        "        self.bilstm = nn.LSTM(\n",
        "            input_size=cnn_out * 3,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.ln_lstm = nn.LayerNorm(lstm_hidden * 2)\n",
        "        self.attn = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_hidden * 2,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.ln_attn = nn.LayerNorm(lstm_hidden * 2)\n",
        "        self.fc = nn.Linear(lstm_hidden * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # (batch, seq, embed_dim)\n",
        "        emb_t = emb.transpose(1, 2)  # (batch, embed_dim, seq)\n",
        "        c3 = F.relu(self.bn3(self.conv3(emb_t)))\n",
        "        c4 = F.relu(self.bn4(self.conv4(emb_t)))\n",
        "        c5 = F.relu(self.bn5(self.conv5(emb_t)))\n",
        "        cnn_cat = torch.cat([c3, c4, c5], dim=1)  # (batch, cnn_out*3, seq)\n",
        "        cnn_cat = cnn_cat.transpose(1, 2)  # (batch, seq, cnn_out*3)\n",
        "        emb_proj = self.proj(emb)  # (batch, seq, cnn_out*3)\n",
        "        x_cnn = cnn_cat + emb_proj\n",
        "        lstm_out, _ = self.bilstm(x_cnn)\n",
        "        lstm_out = self.ln_lstm(lstm_out)\n",
        "        attn_out, _ = self.attn(lstm_out, lstm_out, lstm_out)\n",
        "        attn_out = self.ln_attn(lstm_out + attn_out)\n",
        "        pooled = attn_out.mean(dim=1)\n",
        "        out = self.dropout(pooled)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5qsAbEtn2X3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 5: Training & DDP Setup\n",
        "# =========================\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=3,\n",
        "    lr=2e-3,\n",
        "    grad_clip=5.0,\n",
        "    device='cuda',\n",
        "    gpu_stats_log=None\n",
        "):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_val_acc = 0\n",
        "    best_model_state = None\n",
        "    train_metrics = []\n",
        "    val_metrics = []\n",
        "    gpu_stats = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * X.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = correct / total\n",
        "        train_metrics.append((train_loss, train_acc))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_correct += (preds == y).sum().item()\n",
        "                val_total += y.size(0)\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "        val_metrics.append((val_loss, val_acc))\n",
        "\n",
        "        # GPU stats\n",
        "        stats = get_gpu_stats()\n",
        "        gpu_stats.append({'epoch': epoch, 'stats': stats})\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "    if gpu_stats_log is not None:\n",
        "        gpu_stats_log.extend(gpu_stats)\n",
        "    model.load_state_dict(best_model_state)\n",
        "    return model, train_metrics, val_metrics"
      ],
      "metadata": {
        "id": "LcJefrfk2X5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 6: Grid Search Implementation\n",
        "# =========================\n",
        "\n",
        "from itertools import product\n",
        "\n",
        "def grid_search(train_ds, val_ds, grid_params, device='cuda', batch_size=128, num_epochs=3):\n",
        "    results = []\n",
        "    best_models = []\n",
        "    gpu_stats_all = []\n",
        "    param_combos = list(product(*grid_params.values()))\n",
        "    for idx, combo in enumerate(param_combos):\n",
        "        params = dict(zip(grid_params.keys(), combo))\n",
        "        print(f\"\\nGrid Search {idx+1}/{len(param_combos)}: {params}\")\n",
        "        model = CNN_BiLSTM_Attn(\n",
        "            vocab_size=50000,\n",
        "            embed_dim=128,\n",
        "            cnn_out=150,\n",
        "            lstm_hidden=params['lstm_hidden'],\n",
        "            num_heads=params['num_heads'],\n",
        "            num_classes=5,\n",
        "            dropout=0.3\n",
        "        ).to(device)\n",
        "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "        gpu_stats_log = []\n",
        "        model, train_metrics, val_metrics = train_model(\n",
        "            model, train_loader, val_loader,\n",
        "            num_epochs=num_epochs, lr=params['learning_rate'],\n",
        "            grad_clip=5.0, device=device, gpu_stats_log=gpu_stats_log\n",
        "        )\n",
        "        val_acc = val_metrics[-1][1]\n",
        "        results.append({\n",
        "            'params': params,\n",
        "            'val_acc': val_acc,\n",
        "            'model_state': model.state_dict(),\n",
        "            'gpu_stats': gpu_stats_log\n",
        "        })\n",
        "        gpu_stats_all.append(gpu_stats_log)\n",
        "    # Sort and save top 2 models\n",
        "    results_sorted = sorted(results, key=lambda x: x['val_acc'], reverse=True)\n",
        "    for i, res in enumerate(results_sorted[:2]):\n",
        "        torch.save(res['model_state'], f'best_model_{i+1}.pt')\n",
        "    # Save grid search summary\n",
        "    summary = pd.DataFrame([{'lstm_hidden': r['params']['lstm_hidden'],\n",
        "                             'num_heads': r['params']['num_heads'],\n",
        "                             'learning_rate': r['params']['learning_rate'],\n",
        "                             'val_acc': r['val_acc']} for r in results_sorted])\n",
        "    summary['top2'] = False\n",
        "    summary.loc[:1, 'top2'] = True\n",
        "    summary.to_csv('grid_search_results.csv', index=False)\n",
        "    print(\"\\nGrid Search Summary:\")\n",
        "    display(summary)\n",
        "    return results_sorted, summary, gpu_stats_all"
      ],
      "metadata": {
        "id": "2bfiVHo-2X8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 7: Prediction & Visualization\n",
        "# =========================\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer, device='cuda'):\n",
        "    model.eval()\n",
        "    text_clean = preprocess_text(text)\n",
        "    ids = pad_seq(tokenizer.encode(text_clean).ids, MAX_LEN)\n",
        "    X = torch.tensor([ids], dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(X)\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy().flatten()\n",
        "        pred_class = np.argmax(probs) + 1\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.barplot(x=[1,2,3,4,5], y=probs, palette='viridis')\n",
        "    plt.title(f\"Sentiment Prediction Probabilities\\nPredicted Class: {pred_class} (Confidence: {probs[pred_class-1]:.2f})\")\n",
        "    plt.xlabel(\"Sentiment Class\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.ylim(0,1)\n",
        "    plt.show()\n",
        "    print(f\"Predicted Sentiment: {pred_class} (Confidence: {probs[pred_class-1]:.2f})\")\n",
        "    return pred_class, probs"
      ],
      "metadata": {
        "id": "xBV5LKwi2eOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 8: GPU Utilization Visualization\n",
        "# =========================\n",
        "\n",
        "def plot_gpu_stats(gpu_stats_all):\n",
        "    # Flatten and organize stats\n",
        "    stats_flat = []\n",
        "    for run_idx, run in enumerate(gpu_stats_all):\n",
        "        for epoch_stat in run:\n",
        "            epoch = epoch_stat['epoch']\n",
        "            for gpu_stat in epoch_stat['stats']:\n",
        "                stats_flat.append({\n",
        "                    'run': run_idx,\n",
        "                    'epoch': epoch,\n",
        "                    'gpu': gpu_stat['gpu'],\n",
        "                    'utilization': gpu_stat['utilization'],\n",
        "                    'mem_used': gpu_stat['mem_used'],\n",
        "                    'mem_total': gpu_stat['mem_total']\n",
        "                })\n",
        "    df_stats = pd.DataFrame(stats_flat)\n",
        "    if df_stats.empty:\n",
        "        print(\"No GPU stats to plot.\")\n",
        "        return\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.lineplot(data=df_stats, x='epoch', y='utilization', hue='gpu', style='run', markers=True)\n",
        "    plt.title(\"GPU Utilization Over Epochs\")\n",
        "    plt.ylabel(\"Utilization (%)\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.savefig(\"gpu_utilization.png\")\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.lineplot(data=df_stats, x='epoch', y='mem_used', hue='gpu', style='run', markers=True)\n",
        "    plt.title(\"GPU Memory Usage Over Epochs\")\n",
        "    plt.ylabel(\"Memory Used (MiB)\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.savefig(\"gpu_memory_usage.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uH0eTJZg2eXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell 9: Example Usage\n",
        "# =========================\n",
        "\n",
        "# Set device and grid search params\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "fast_grid_params = {\n",
        "    'lstm_hidden': [128, 192],\n",
        "    'num_heads': [6, 8],\n",
        "    'learning_rate': [2e-3]\n",
        "}\n",
        "\n",
        "# Run grid search (uses 200K records, 3 epochs per run)\n",
        "results_sorted, summary, gpu_stats_all = grid_search(\n",
        "    train_ds, val_ds, fast_grid_params, device=device, batch_size=128, num_epochs=3\n",
        ")\n",
        "\n",
        "# Load best model for prediction\n",
        "best_model = CNN_BiLSTM_Attn(\n",
        "    vocab_size=50000,\n",
        "    embed_dim=128,\n",
        "    cnn_out=150,\n",
        "    lstm_hidden=int(summary.iloc[0]['lstm_hidden']),\n",
        "    num_heads=int(summary.iloc[0]['num_heads']),\n",
        "    num_classes=5,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "best_model.load_state_dict(torch.load('best_model_1.pt'))\n",
        "\n",
        "# Example prediction\n",
        "sample_text = \"This book was absolutely fantastic! I loved every page.\"\n",
        "predict_sentiment(sample_text, best_model, bpe_tokenizer, device=device)\n",
        "\n",
        "# Plot GPU stats\n",
        "plot_gpu_stats(gpu_stats_all)"
      ],
      "metadata": {
        "id": "7dFaaEgn2ebo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1MaFly42eep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2rmmvU12X_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pc8w1Vmk2YB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJvMpoCm2YEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQhLHK2S2YH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}